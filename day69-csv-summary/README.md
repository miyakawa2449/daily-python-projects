# ğŸ“Š CSV ãƒ‡ãƒ¼ã‚¿é›†è¨ˆãƒ»åˆ†æãƒ„ãƒ¼ãƒ« (CSV Summary)

pandasã‚’ä½¿ç”¨ã—ã¦CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã€åŸºæœ¬çµ±è¨ˆé‡ã®è¡¨ç¤ºã€ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆã‚’è¡Œã†ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ã€Œãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã¨ã—ã¦ã®pandasã®å¨åŠ›ã‚’ä½“æ„Ÿã§ãã‚‹å®Ÿè·µçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚

## ğŸ“š **pandasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¤ã„ã¦**

**pandas**ã¯ã€Œ**Pythonã§ã®ãƒ‡ãƒ¼ã‚¿æ“ä½œã‚„åˆ†æã‚’åŠ¹ç‡åŒ–ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**ã€ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®åŸºç›¤æŠ€è¡“ã§ã™ã€‚

### ğŸ—ï¸ **ãƒ¡ã‚¤ãƒ³ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ **

| ãƒ‡ãƒ¼ã‚¿æ§‹é€  | èª¬æ˜ | ä¾‹ |
|---------|------|-----|
| **DataFrame** | è¡Œã¨åˆ—ã§æ§‹æˆã•ã‚Œã‚‹äºŒæ¬¡å…ƒã®è¡¨ï¼ˆExcelã¿ãŸã„ãªã‚‚ã®ï¼‰ | `df = pd.DataFrame(data)` |
| **Series** | ä¸€åˆ—ã ã‘ã®ä¸€æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ï¼ˆåˆ—ã‚„è¡Œã®éƒ¨åˆ†ãƒ‡ãƒ¼ã‚¿ï¼‰ | `series = df['Column']` |

### âš¡ **pandasã§ã§ãã‚‹ã“ã¨**

| å‡¦ç† | èª¬æ˜ | ä¸»ãªãƒ¡ã‚½ãƒƒãƒ‰ |
|------|------|------------|
| **CSVã‚„Excel, JSON, SQL ãªã©ã®èª­ã¿æ›¸ã** | æ§˜ã€…ãªå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç°¡å˜ã«èª­ã¿è¾¼ã¿ãƒ»ä¿å­˜ | `read_csv()`, `read_excel()`, `read_sql()`, `to_csv()` |
| **ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºãƒ»ä¸¦ã¹æ›¿ãˆ** | æ¡ä»¶ã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ã‚½ãƒ¼ãƒˆ | `.loc[]`, `.query()`, `.sort_values()` |
| **ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆ** | ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã‚„çµ±è¨ˆçš„é›†è¨ˆã€ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ | `.groupby()`, `.agg()`, `.pivot_table()` |
| **æ¬ æå€¤å‡¦ç†** | ãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤æ¤œå‡ºãƒ»è£œå®Œãƒ»å‰Šé™¤ | `.isnull()`, `.fillna()`, `.dropna()` |
| **ãƒ‡ãƒ¼ã‚¿ã®çµåˆ** | è¤‡æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±åˆãƒ»ãƒãƒ¼ã‚¸ | `.merge()`, `.concat()` |
| **ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆè¨ˆç®—** | å¹³å‡ã€åˆ†æ•£ã€åˆè¨ˆã€æœ€å¤§æœ€å°ã€ã‚«ã‚¦ãƒ³ãƒˆ ãªã© | `.mean()`, `.sum()`, `.describe()`, `.count()` |
| **ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–** | matplotlib ã¨é€£æºã—ã¦ç°¡å˜ã«ã‚°ãƒ©ãƒ•åŒ– | `.plot()`, `.hist()`, `.scatter()` |

## ğŸ“ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ¦‚è¦

**ä¸»ãªæ©Ÿèƒ½**:
- **CSVè‡ªå‹•èª­ã¿è¾¼ã¿**: pandasã«ã‚ˆã‚‹1è¡Œã§ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
- **ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª**: head()ã«ã‚ˆã‚‹å…ˆé ­ãƒ‡ãƒ¼ã‚¿ã®å³åº§è¡¨ç¤º
- **çµ±è¨ˆé‡è‡ªå‹•è¨ˆç®—**: describe()ã«ã‚ˆã‚‹8ã¤ã®åŸºæœ¬çµ±è¨ˆé‡ã®ä¸€æ‹¬ç®—å‡º
- **ã‚°ãƒ«ãƒ¼ãƒ—åŒ–é›†è¨ˆ**: SQLçš„ãªGROUP BYæ“ä½œã«ã‚ˆã‚‹ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆè¨ˆ
- **çµæœä¿å­˜**: é›†è¨ˆçµæœã®è‡ªå‹•CSVå‡ºåŠ›

**å­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ**:
- pandasã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆpdï¼‰ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- DataFrameã¨Seriesã®é•ã„ã¨reset_index()ã®é‡è¦æ€§
- SQLãƒ©ã‚¤ã‚¯ãªãƒ‡ãƒ¼ã‚¿æ“ä½œã®å®Ÿè·µ
- ã€Œãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã¨ã—ã¦ã®pandasæ´»ç”¨

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
day69-csv-summary/
â”œâ”€â”€ main.py          # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ï¼ˆpandasæ´»ç”¨ï¼‰
â”œâ”€â”€ sample.csv       # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆè³¼è²·å±¥æ­´ï¼‰
â”œâ”€â”€ summary.csv      # å‡ºåŠ›çµæœï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆï¼‰
â””â”€â”€ README.md        # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

### ğŸ¯ **ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²**

#### **main.py**
```python
import pandas as pd  # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ä½¿ç”¨ã§ã‚³ãƒ¼ãƒ‰ç°¡æ½”åŒ–

def summarize_csv(filename="sample.csv"):
    # 1. CSVèª­ã¿è¾¼ã¿ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ¼ãƒ—ãƒ³ä¸è¦ï¼‰
    df = pd.read_csv(filename)
    
    # 2. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ç¢ºèª
    print(df.head())
    
    # 3. çµ±è¨ˆé‡ä¸€æ‹¬è¨ˆç®—
    print(df.describe())
    
    # 4. SQLãƒ©ã‚¤ã‚¯ãªGROUP BYæ“ä½œ
    grouped = df.groupby('Category')['Amount'].sum().reset_index()
    
    # 5. çµæœä¿å­˜
    grouped.to_csv("summary.csv", index=False)
```

#### **sample.csvï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰**
```csv
Date,Category,Item,Amount
2025-07-05,Food,Burger,500
2025-07-05,Food,Pizza,800
2025-07-05,Drink,Coffee,300
...ï¼ˆè³¼è²·å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼‰
```

#### **summary.csvï¼ˆå‡ºåŠ›çµæœï¼‰**
```csv
Category,Amount
Drink,1500
Food,3200
Goods,1700
```

## ğŸš€ å®Ÿè¡Œæ–¹æ³•

### ğŸ“‹ **å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**

```bash
# condaã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
conda install pandas

# ã¾ãŸã¯ pip ã‚’ä½¿ç”¨
pip install pandas
```

**ãªãœcondaãŒæ¨å¥¨ï¼Ÿ**:
- **ä¾å­˜é–¢ä¿‚æœ€é©åŒ–**: ç§‘å­¦è¨ˆç®—ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æœ€é©ãªçµ„ã¿åˆã‚ã›
- **ãƒã‚¤ãƒŠãƒªæä¾›**: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã§é«˜é€Ÿå‹•ä½œ
- **ç’°å¢ƒæ•´åˆæ€§**: condaç’°å¢ƒå…¨ä½“ã§ã®äº’æ›æ€§ç¢ºä¿

### ğŸ’» **å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰**

```bash
cd day69-csv-summary
python main.py
```

### ğŸ“Š **å®Ÿè¡Œçµæœã®ä¾‹**

```
ğŸ“‚ èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«: sample.csv

âœ… ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­5è¡Œ:
         Date Category   Item  Amount
0  2025-07-05     Food  Burger     500
1  2025-07-05     Food   Pizza     800
2  2025-07-05    Drink  Coffee     300
3  2025-07-05    Drink    Tea     200
4  2025-07-06     Food   Sushi    1200

ğŸ“Š åˆ—ã”ã¨ã®åŸºæœ¬çµ±è¨ˆé‡:
            Amount
count     10.000000
mean     620.000000
std      418.330013
min      200.000000
25%      350.000000
50%      550.000000
75%      762.500000
max     1500.000000

ğŸ“ˆ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆè¨ˆ:
  Category  Amount
0    Drink    1500
1     Food    3200
2    Goods    1700

ğŸ’¾ summary.csv ã«ä¿å­˜ã—ã¾ã—ãŸï¼
```

## ğŸ’¡ ä½¿ã„æ–¹

### ğŸ® **åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•**

#### **1. è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™**
```python
# ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«æŒ‡å®š
summarize_csv("my_data.csv")
```

#### **2. å¿…è¦ãªåˆ—æ§‹æˆ**
```csv
# æœ€ä½é™å¿…è¦ãªåˆ—
Category,Amount
é£Ÿè²»,1200
äº¤é€šè²»,800
...
```

### ğŸ¯ **å¿œç”¨çš„ãªä½¿ç”¨æ–¹æ³•**

#### **1. è¤‡æ•°ã®é›†è¨ˆã‚’åŒæ™‚å®Ÿè¡Œ**
```python
# main.py ã‚’æ‹¡å¼µ
grouped_multi = df.groupby('Category')['Amount'].agg([
    'sum',      # åˆè¨ˆ
    'mean',     # å¹³å‡
    'count',    # ä»¶æ•°
    'min',      # æœ€å°
    'max'       # æœ€å¤§
]).reset_index()
```

#### **2. æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**
```python
# 500å††ä»¥ä¸Šã®å•†å“ã®ã¿é›†è¨ˆ
expensive = df[df['Amount'] >= 500]
result = expensive.groupby('Category')['Amount'].sum().reset_index()
```

#### **3. æ—¥ä»˜åˆ¥åˆ†æ**
```python
# æ—¥ä»˜åˆ¥é›†è¨ˆ
daily_summary = df.groupby('Date')['Amount'].sum().reset_index()
```

## ğŸ“ **pandasã®è±Šå¯Œãªæ©Ÿèƒ½æ´»ç”¨ä¾‹**

### ğŸ“ˆ **ä»Šå›ä½¿ç”¨ã—ãŸæ©Ÿèƒ½**

```python
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
df = pd.read_csv("sample.csv")              # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿

# 2. ãƒ‡ãƒ¼ã‚¿ç¢ºèª
print(df.head())                            # å…ˆé ­ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
print(df.describe())                        # çµ±è¨ˆé‡è¨ˆç®—

# 3. ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
grouped = df.groupby('Category')['Amount'].sum()  # ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã¨é›†è¨ˆ

# 4. ãƒ‡ãƒ¼ã‚¿ä¿å­˜
grouped.to_csv("summary.csv", index=False) # CSVå‡ºåŠ›
```

### ğŸš€ **pandasã®ä»–ã®å¼·åŠ›ãªæ©Ÿèƒ½**

#### **1. å¤šæ§˜ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å¯¾å¿œ**
```python
# Excelèª­ã¿è¾¼ã¿
df = pd.read_excel("data.xlsx")

# JSONèª­ã¿è¾¼ã¿
df = pd.read_json("data.json")

# SQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql("SELECT * FROM table", conn)
```

#### **2. ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°**
```python
# æ¡ä»¶æŒ‡å®šã§ã®æŠ½å‡º
expensive_food = df[(df['Category'] == 'Food') & (df['Amount'] >= 1000)]

# ã‚¯ã‚¨ãƒªå½¢å¼ã§ã®æŠ½å‡º
result = df.query("Category == 'Food' and Amount >= 1000")

# ç‰¹å®šã®åˆ—ã®ã¿é¸æŠ
subset = df[['Category', 'Amount']]

# ä½ç½®æŒ‡å®šã§ã®æŠ½å‡º
data = df.loc[0:5, 'Category':'Amount']
```

#### **3. ãƒ‡ãƒ¼ã‚¿ã®ä¸¦ã³æ›¿ãˆ**
```python
# å˜ä¸€åˆ—ã§ã‚½ãƒ¼ãƒˆ
df_sorted = df.sort_values('Amount', ascending=False)

# è¤‡æ•°åˆ—ã§ã‚½ãƒ¼ãƒˆ
df_sorted = df.sort_values(['Category', 'Amount'], ascending=[True, False])
```

#### **4. æ¬ æå€¤å‡¦ç†**
```python
# æ¬ æå€¤ã®ç¢ºèª
print(df.isnull().sum())

# æ¬ æå€¤ã®è£œå®Œ
df_filled = df.fillna(df.mean())  # å¹³å‡å€¤ã§è£œå®Œ
df_filled = df.fillna(0)          # ã‚¼ãƒ­ã§è£œå®Œ

# æ¬ æå€¤ã®å‰Šé™¤
df_clean = df.dropna()
```

#### **5. ãƒ‡ãƒ¼ã‚¿ã®çµåˆ**
```python
# 2ã¤ã®DataFrameã‚’çµåˆ
df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['A', 'B', 'C']})
df2 = pd.DataFrame({'ID': [1, 2, 3], 'Score': [85, 92, 78]})

# ãƒãƒ¼ã‚¸ï¼ˆJOINç›¸å½“ï¼‰
merged = df1.merge(df2, on='ID')

# ç¸¦æ–¹å‘ã®çµåˆï¼ˆUNIONç›¸å½“ï¼‰
combined = pd.concat([df1, df2], ignore_index=True)
```

#### **6. é«˜åº¦ãªé›†è¨ˆå‡¦ç†**
```python
# è¤‡æ•°ã®çµ±è¨ˆé‡ã‚’åŒæ™‚è¨ˆç®—
summary = df.groupby('Category')['Amount'].agg([
    'count', 'sum', 'mean', 'median', 'std', 'min', 'max'
])

# ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«
pivot = df.pivot_table(
    values='Amount',
    index='Date',
    columns='Category',
    aggfunc='sum',
    fill_value=0
)

# ã‚¯ãƒ­ã‚¹é›†è¨ˆ
crosstab = pd.crosstab(df['Category'], df['Date'])
```

#### **7. ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–**
```python
import matplotlib.pyplot as plt

# åŸºæœ¬çš„ãªã‚°ãƒ©ãƒ•
df.groupby('Category')['Amount'].sum().plot(kind='bar')
plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆè¨ˆ')
plt.show()

# æ•£å¸ƒå›³
df.plot.scatter(x='Date', y='Amount')

# ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
df['Amount'].hist(bins=20)

# ç®±ã²ã’å›³
df.boxplot(column='Amount', by='Category')
```

## ğŸ“– å­¦ã‚“ã ã“ã¨ã‚„ä»Šå¾Œã®æ”¹å–„æ¡ˆï¼ˆå­¦ç¿’ãƒ­ã‚°ï¼‰

### ğŸ”§ ä¸»è¦ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ

#### 1ï¸âƒ£ **pandasã‚¨ã‚¤ãƒªã‚¢ã‚¹ã®å¨åŠ›**

**`import pandas as pd` ã®æ„å‘³ã¨ä¾¡å€¤**:

##### ğŸ¯ **ãªãœ pd ã¨ã„ã†åˆ¥åã‚’ä½¿ã†ã®ã‹**
```python
# âŒ ã‚¨ã‚¤ãƒªã‚¢ã‚¹ãªã—ï¼ˆå†—é•·ï¼‰
import pandas
df = pandas.read_csv("data.csv")
result = pandas.DataFrame(data)

# âœ… ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚ã‚Šï¼ˆç°¡æ½”ï¼‰
import pandas as pd
df = pd.read_csv("data.csv")
result = pd.DataFrame(data)
```

**å­¦ç¿’æˆæœ**:
- **æ¥­ç•Œæ¨™æº–**: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç•Œã§ `pd` ã¯å…±é€šè¨€èª
- **åŠ¹ç‡å‘ä¸Š**: ã‚¿ã‚¤ãƒ”ãƒ³ã‚°é‡å‰Šæ¸›ã¨å¯èª­æ€§å‘ä¸Š
- **ä¸€è²«æ€§**: numpyï¼ˆnpï¼‰ã€matplotlibï¼ˆpltï¼‰ã¨ã®çµ±ä¸€æ„Ÿ

##### ğŸ“Š **ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¨ã‚¤ãƒªã‚¢ã‚¹é›†**
```python
import pandas as pd              # ãƒ‡ãƒ¼ã‚¿åˆ†æ
import numpy as np               # æ•°å€¤è¨ˆç®—  
import matplotlib.pyplot as plt  # ã‚°ãƒ©ãƒ•æç”»
import seaborn as sns            # çµ±è¨ˆå¯è¦–åŒ–
```

#### 2ï¸âƒ£ **pd.read_csv()ã®é­”æ³•çš„ä¾¿åˆ©ã•**

**å¾“æ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† vs pandasã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**:

##### ğŸ˜° **å¾“æ¥ã®æ–¹æ³•ï¼ˆæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼‰**
```python
import csv

data = []
with open("sample.csv", "r", encoding="utf-8") as file:
    reader = csv.DictReader(file)
    for row in reader:
        # æ‰‹å‹•ã§å‹å¤‰æ›
        row['Amount'] = int(row['Amount'])
        data.append(row)

# ã•ã‚‰ã«æ‰‹å‹•ã§ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–...
```

##### âœ¨ **pandasã®æ–¹æ³•**
```python
df = pd.read_csv("sample.csv")
# â†‘ ã“ã®1è¡Œã§ä»¥ä¸‹ã‚’å…¨ã¦è‡ªå‹•å®Ÿè¡Œ:
# 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ¼ãƒ—ãƒ³
# 2. CSVè§£æ
# 3. ãƒ‡ãƒ¼ã‚¿å‹è‡ªå‹•æ¨å®š
# 4. æ§‹é€ åŒ–ï¼ˆDataFrameä½œæˆï¼‰
# 5. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒ­ãƒ¼ã‚º
# 6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```

**é‡è¦ãªæ°—ã¥ã**:
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ¼ãƒ—ãƒ³ä¸è¦**: with openæ–‡ãªã©ã®ç…©é›‘ãªå‡¦ç†ãŒä¸è¦
- **å‹æ¨å®šã®è‡ªå‹•åŒ–**: æ–‡å­—åˆ—ã€æ•°å€¤ã€æ—¥ä»˜ã‚’è‡ªå‹•åˆ¤åˆ¥
- **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ**: UTF-8ãªã©ã®æ–‡å­—åŒ–ã‘å•é¡Œã‚’è‡ªå‹•è§£æ±º

##### ğŸš€ **ã•ã‚‰ã«é«˜åº¦ãªæ©Ÿèƒ½**
```python
# åŒºåˆ‡ã‚Šæ–‡å­—æŒ‡å®š
df = pd.read_csv("data.tsv", sep="\t")

# ç‰¹å®šåˆ—ã®ã¿èª­ã¿è¾¼ã¿
df = pd.read_csv("data.csv", usecols=["Category", "Amount"])

# æ¬ æå€¤ã®æŒ‡å®š
df = pd.read_csv("data.csv", na_values=["N/A", "null", ""])
```

#### 3ï¸âƒ£ **df.head()ã®æŸ”è»Ÿãªæ´»ç”¨**

**ãƒ‡ãƒ¼ã‚¿ç¢ºèªã®åŸºæœ¬ãƒ„ãƒ¼ãƒ«**:

##### ğŸ“‹ **åŸºæœ¬çš„ãªä½¿ã„æ–¹**
```python
df.head()     # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…ˆé ­5è¡Œ
df.head(3)    # å…ˆé ­3è¡Œ
df.head(10)   # å…ˆé ­10è¡Œ
df.head(1)    # å…ˆé ­1è¡Œã®ã¿
```

##### ğŸ¯ **ãªãœhead()ãŒé‡è¦ã‹**
```python
# å¤§é‡ãƒ‡ãƒ¼ã‚¿ã§ã‚‚å®‰å…¨ã«ç¢ºèª
df = pd.read_csv("huge_file_1million_rows.csv")
print(df.head())  # æ•°ç§’ã§å…ˆé ­5è¡Œã®ã¿è¡¨ç¤º

# ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å³åº§æŠŠæ¡
print(df.head())
# â†’ åˆ—åã€ãƒ‡ãƒ¼ã‚¿å‹ã€å€¤ã®ä¾‹ã‚’ç¬æ™‚ã«ç†è§£
```

##### ğŸ” **å¯¾ã«ãªã‚‹ãƒ¡ã‚½ãƒƒãƒ‰**
```python
df.head()     # å…ˆé ­ã‹ã‚‰5è¡Œ
df.tail()     # æœ«å°¾ã‹ã‚‰5è¡Œ

# ãƒ‡ãƒ¼ã‚¿å…¨ä½“ã®æ¦‚è¦æŠŠæ¡
print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
print(f"å½¢çŠ¶: {df.shape}")
print("\nå…ˆé ­5è¡Œ:")
print(df.head())
print("\næœ«å°¾5è¡Œ:")
print(df.tail())
```

#### 4ï¸âƒ£ **df.describe()ã®åœ§å€’çš„ãªå¨åŠ›**

**1è¡Œã§8ã¤ã®çµ±è¨ˆé‡ã‚’è‡ªå‹•è¨ˆç®—**:

##### ğŸ“Š **describe()ãŒè¨ˆç®—ã™ã‚‹çµ±è¨ˆé‡**
```python
df.describe()
# â†“ è‡ªå‹•è¨ˆç®—ã•ã‚Œã‚‹é …ç›®
# count: ãƒ‡ãƒ¼ã‚¿å€‹æ•°ï¼ˆæ¬ æå€¤é™¤ãï¼‰
# mean:  å¹³å‡å€¤
# std:   æ¨™æº–åå·®ï¼ˆãƒ‡ãƒ¼ã‚¿ã®ã°ã‚‰ã¤ãï¼‰
# min:   æœ€å°å€¤
# 25%:   ç¬¬1å››åˆ†ä½æ•°ï¼ˆä¸‹ä½25%ã®å¢ƒç•Œï¼‰
# 50%:   ä¸­å¤®å€¤ï¼ˆç¬¬2å››åˆ†ä½æ•°ï¼‰
# 75%:   ç¬¬3å››åˆ†ä½æ•°ï¼ˆä¸Šä½25%ã®å¢ƒç•Œï¼‰
# max:   æœ€å¤§å€¤
```

##### ğŸ˜± **æ‰‹å‹•è¨ˆç®—ã ã£ãŸã‚‰åœ°ç„**
```python
# ã‚‚ã—describe()ãŒãªã‹ã£ãŸã‚‰...
count = len(df['Amount'])
mean = df['Amount'].sum() / len(df['Amount'])
std = np.std(df['Amount'], ddof=1)
min_val = df['Amount'].min()
q25 = df['Amount'].quantile(0.25)
median = df['Amount'].median()
q75 = df['Amount'].quantile(0.75)
max_val = df['Amount'].max()
# 8ã¤ã®çµ±è¨ˆé‡ã‚’æ‰‹å‹•è¨ˆç®—... ğŸ˜­
```

##### ğŸ¯ **ãƒ“ã‚¸ãƒã‚¹æ´»ç”¨ä¾‹**
```python
stats = df.describe()

# ç•°å¸¸å€¤æ¤œå‡º
if stats.loc['max', 'Amount'] > stats.loc['75%', 'Amount'] * 3:
    print("âš ï¸ ç•°å¸¸ã«é«˜ã„å€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

# ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
total_rows = len(df)
valid_data = stats.loc['count', 'Amount']
missing_data = total_rows - valid_data
print(f"ãƒ‡ãƒ¼ã‚¿å®Œæ•´æ€§: {valid_data/total_rows*100:.1f}%")
```

#### 5ï¸âƒ£ **ã‚°ãƒ«ãƒ¼ãƒ—åŒ–å‡¦ç†ã®æ·±ã„ç†è§£**

**SQLãƒ©ã‚¤ã‚¯ãªGROUP BYæ“ä½œ**:

##### ğŸ” **å‡¦ç†ã®4æ®µéšè©³ç´°è§£æ**
```python
grouped = df.groupby('Category')['Amount'].sum().reset_index()
# â†‘ ã“ã®1è¡Œã‚’4ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£
```

**Step 1: ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘**
```python
df.groupby('Category')
# â†’ ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ‡ãƒ¼ã‚¿ã‚’è«–ç†çš„ã«åˆ†å‰²

# å…ƒãƒ‡ãƒ¼ã‚¿:
#   Category  Amount
# 0     Food     500
# 1     Food     800
# 2    Drink     300
# 3    Drink     200

# ã‚°ãƒ«ãƒ¼ãƒ—åˆ†ã‘å¾Œï¼ˆæ¦‚å¿µçš„ï¼‰:
# Food ã‚°ãƒ«ãƒ¼ãƒ—:  [500, 800]
# Drink ã‚°ãƒ«ãƒ¼ãƒ—: [300, 200]
```

**Step 2: åˆ—é¸æŠ**
```python
df.groupby('Category')['Amount']
# â†’ å„ã‚°ãƒ«ãƒ¼ãƒ—ã®Amountåˆ—ã®ã¿æŠ½å‡º
```

**Step 3: é›†è¨ˆå®Ÿè¡Œ**
```python
df.groupby('Category')['Amount'].sum()
# â†’ å„ã‚°ãƒ«ãƒ¼ãƒ—ã®åˆè¨ˆè¨ˆç®—
# Food:  500 + 800 = 1300
# Drink: 300 + 200 = 500

# çµæœ: Seriesã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
# Category
# Drink     500
# Food     1300
# Name: Amount, dtype: int64
```

**Step 4: å½¢å¼å¤‰æ›**
```python
df.groupby('Category')['Amount'].sum().reset_index()
# â†’ Seriesã‚’DataFrameã«å¤‰æ›

# çµæœ: DataFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
#   Category  Amount
# 0    Drink     500
# 1     Food    1300
```

##### ğŸ¤” **ãªãœreset_index()ãŒé‡è¦ï¼Ÿ**

**Series vs DataFrameã®å®Ÿç”¨çš„é•ã„**:

```python
# reset_index()ãªã—ï¼ˆSeriesï¼‰
result_series = df.groupby('Category')['Amount'].sum()
print(type(result_series))  # <class 'pandas.core.series.Series'>

# åˆ¶é™ã•ã‚ŒãŸæ“ä½œ
print(result_series['Category'])  # âŒ ã‚¨ãƒ©ãƒ¼ï¼åˆ—ã§ã¯ãªãã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
new_col = result_series['Amount'] * 1.1  # âŒ ã‚¨ãƒ©ãƒ¼ï¼Amountåˆ—ãŒå­˜åœ¨ã—ãªã„

# reset_index()ã‚ã‚Šï¼ˆDataFrameï¼‰
result_df = df.groupby('Category')['Amount'].sum().reset_index()
print(type(result_df))  # <class 'pandas.core.frame.DataFrame'>

# æŸ”è»Ÿãªæ“ä½œ
print(result_df['Category'])  # âœ… OKï¼
result_df['Tax'] = result_df['Amount'] * 0.1  # âœ… æ–°åˆ—è¿½åŠ ã‚‚ç°¡å˜
result_df.to_csv("output.csv", index=False)   # âœ… CSVä¿å­˜ã‚‚ç¶ºéº—
```

##### ğŸ”„ **SQL vs pandas ã®å¯¾å¿œé–¢ä¿‚**

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã¨ã®å®Œå…¨å¯¾å¿œ**:

```sql
-- SQLæ–‡
SELECT Category, SUM(Amount) as Amount
FROM table 
GROUP BY Category;
```

```python
# pandasï¼ˆå®Œå…¨ã«åŒã˜çµæœï¼‰
df.groupby('Category')['Amount'].sum().reset_index()
```

**ãã®ä»–ã®SQLæ“ä½œã¨ã®å¯¾å¿œ**:
```python
# WHEREå¥
df[df['Amount'] >= 500]

# ORDER BYå¥  
df.sort_values('Amount', ascending=False)

# HAVINGå¥ï¼ˆGROUP BYå¾Œã®æ¡ä»¶ï¼‰
grouped = df.groupby('Category')['Amount'].sum().reset_index()
grouped[grouped['Amount'] >= 1000]

# COUNT(*)
df.groupby('Category').size().reset_index(name='count')
```

#### 6ï¸âƒ£ **ã€Œãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã¨ã—ã¦ã®pandas**

**pandasã®é©å‘½çš„ä¾¡å€¤**:

##### ğŸ—„ï¸ **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®æ§‹é€ å¯¾å¿œ**
```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”¨èª â†â†’ pandasç”¨èª
# ãƒ†ãƒ¼ãƒ–ãƒ«        â†â†’ DataFrame
# ãƒ¬ã‚³ãƒ¼ãƒ‰(è¡Œ)     â†â†’ row/index
# ã‚«ãƒ©ãƒ (åˆ—)      â†â†’ column
# PRIMARY KEY    â†â†’ index
# JOIN          â†â†’ merge/join
# SQLæ–‡         â†â†’ pandasãƒ¡ã‚½ãƒƒãƒ‰
```

##### âš¡ **pandasã®å„ªä½æ€§**
```python
# 1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
result = df.groupby('Category')['Amount'].sum()  # ç¬æ™‚å®Ÿè¡Œ

# 2. ãƒã‚§ãƒ¼ãƒ³æ“ä½œ
result = (df
    .groupby('Category')['Amount']
    .sum()
    .reset_index()
    .sort_values('Amount', ascending=False)
    .head(3)
)

# 3. æŸ”è»Ÿãªåˆ—æ“ä½œ
df['Price_Per_Char'] = df['Amount'] / df['Item'].str.len()
df['Category_Rank'] = df.groupby('Category')['Amount'].rank()
```

##### ğŸ“Š **é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ**
```python
# ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆPIVOTç›¸å½“ï¼‰
pivot = df.pivot_table(
    values='Amount', 
    index='Date', 
    columns='Category', 
    aggfunc='sum',
    fill_value=0
)

# ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é–¢æ•°çš„æ“ä½œ
df['Cumulative'] = df.groupby('Category')['Amount'].cumsum()
df['Moving_Avg'] = df.groupby('Category')['Amount'].rolling(2).mean()

# ã‚µãƒ–ã‚¯ã‚¨ãƒªçš„æ“ä½œ
category_avg = df.groupby('Category')['Amount'].mean()
df['Above_Avg'] = df.apply(
    lambda row: row['Amount'] > category_avg[row['Category']], 
    axis=1
)
```

## ğŸš€ ä»Šå¾Œã®æ”¹å–„ãƒ»ç™ºå±•ã‚¢ã‚¤ãƒ‡ã‚¢

#### ğŸ“ˆ **æ©Ÿèƒ½æ‹¡å¼µæ¡ˆ**

##### 1ï¸âƒ£ **å¤šæ§˜ãªé›†è¨ˆæ©Ÿèƒ½**
```python
def advanced_summary(filename):
    df = pd.read_csv(filename)
    
    # è¤‡æ•°ã®é›†è¨ˆã‚’åŒæ™‚å®Ÿè¡Œ
    summary = df.groupby('Category')['Amount'].agg([
        'count',    # ä»¶æ•°
        'sum',      # åˆè¨ˆ
        'mean',     # å¹³å‡
        'median',   # ä¸­å¤®å€¤
        'std',      # æ¨™æº–åå·®
        'min',      # æœ€å°
        'max'       # æœ€å¤§
    ]).round(2).reset_index()
    
    # æ§‹æˆæ¯”è¨ˆç®—
    summary['percentage'] = (summary['sum'] / summary['sum'].sum()) * 100
    
    return summary
```

##### 2ï¸âƒ£ **æ™‚ç³»åˆ—åˆ†ææ©Ÿèƒ½**
```python
def time_series_analysis(filename):
    df = pd.read_csv(filename)
    
    # æ—¥ä»˜åˆ—ã‚’datetimeå‹ã«å¤‰æ›
    df['Date'] = pd.to_datetime(df['Date'])
    
    # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
    daily_trend = df.groupby('Date')['Amount'].sum().reset_index()
    
    # ç§»å‹•å¹³å‡
    daily_trend['Moving_Avg_3'] = daily_trend['Amount'].rolling(3).mean()
    
    # å‰æ—¥æ¯”
    daily_trend['Change'] = daily_trend['Amount'].pct_change() * 100
    
    return daily_trend
```

##### 3ï¸âƒ£ **ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–æ©Ÿèƒ½**
```python
import matplotlib.pyplot as plt
import seaborn as sns

def visualize_data(filename):
    df = pd.read_csv(filename)
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥å††ã‚°ãƒ©ãƒ•
    category_sum = df.groupby('Category')['Amount'].sum()
    plt.figure(figsize=(10, 6))
    
    plt.subplot(1, 2, 1)
    plt.pie(category_sum.values, labels=category_sum.index, autopct='%1.1f%%')
    plt.title('ã‚«ãƒ†ã‚´ãƒªåˆ¥æ§‹æˆæ¯”')
    
    # æ—¥åˆ¥æ¨ç§»
    plt.subplot(1, 2, 2)
    daily_sum = df.groupby('Date')['Amount'].sum()
    plt.plot(daily_sum.index, daily_sum.values, marker='o')
    plt.title('æ—¥åˆ¥æ¨ç§»')
    plt.xticks(rotation=45)
    
    plt.tight_layout()
    plt.savefig('analysis_result.png')
    plt.show()
```

##### 4ï¸âƒ£ **å¤–ã‚Œå€¤æ¤œå‡ºãƒ»ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°**
```python
def detect_outliers(filename):
    df = pd.read_csv(filename)
    
    # IQRæ³•ã«ã‚ˆã‚‹å¤–ã‚Œå€¤æ¤œå‡º
    Q1 = df['Amount'].quantile(0.25)
    Q3 = df['Amount'].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    outliers = df[(df['Amount'] < lower_bound) | (df['Amount'] > upper_bound)]
    
    print(f"å¤–ã‚Œå€¤æ¤œå‡º: {len(outliers)}ä»¶")
    print(outliers)
    
    # ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
    cleaned_df = df[(df['Amount'] >= lower_bound) & (df['Amount'] <= upper_bound)]
    
    return cleaned_df, outliers
```

##### 5ï¸âƒ£ **ãƒ¬ãƒãƒ¼ãƒˆè‡ªå‹•ç”Ÿæˆ**
```python
def generate_report(filename):
    df = pd.read_csv(filename)
    
    report = f"""
ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
={'='*50}

ğŸ“‹ åŸºæœ¬æƒ…å ±:
  â€¢ ãƒ‡ãƒ¼ã‚¿æœŸé–“: {df['Date'].min()} ï½ {df['Date'].max()}
  â€¢ ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df):,}ä»¶
  â€¢ ã‚«ãƒ†ã‚´ãƒªæ•°: {df['Category'].nunique()}ç¨®é¡
  â€¢ ç·é‡‘é¡: {df['Amount'].sum():,}å††

ğŸ“ˆ çµ±è¨ˆã‚µãƒãƒªãƒ¼:
  â€¢ å¹³å‡é‡‘é¡: {df['Amount'].mean():.0f}å††
  â€¢ ä¸­å¤®å€¤: {df['Amount'].median():.0f}å††
  â€¢ æœ€é«˜é¡: {df['Amount'].max():,}å††
  â€¢ æœ€ä½é¡: {df['Amount'].min():,}å††

ğŸ† ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ©ãƒ³ã‚­ãƒ³ã‚°:
"""
    
    category_ranking = df.groupby('Category')['Amount'].sum().sort_values(ascending=False)
    for i, (category, amount) in enumerate(category_ranking.items(), 1):
        percentage = (amount / df['Amount'].sum()) * 100
        report += f"  {i}. {category}: {amount:,}å†† ({percentage:.1f}%)\n"
    
    # ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    with open('analysis_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(report)
    return report
```

#### ğŸ”§ **æŠ€è¡“çš„æ”¹å–„æ¡ˆ**

##### 1ï¸âƒ£ **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ**
```python
import json

def load_config():
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    config = {
        "input_file": "sample.csv",
        "output_file": "summary.csv",
        "group_by_column": "Category",
        "aggregate_column": "Amount",
        "aggregate_functions": ["sum", "mean", "count"],
        "include_statistics": True,
        "create_visualization": False
    }
    
    try:
        with open('config.json', 'r') as f:
            user_config = json.load(f)
            config.update(user_config)
    except FileNotFoundError:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§å®Ÿè¡Œ
        pass
    
    return config
```

##### 2ï¸âƒ£ **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–**
```python
def robust_csv_analysis(filename):
    """å …ç‰¢ãªCSVåˆ†æ"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        if not os.path.exists(filename):
            raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # CSVèª­ã¿è¾¼ã¿
        df = pd.read_csv(filename)
        
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        if df.empty:
            raise ValueError("CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™")
        
        if len(df.columns) < 2:
            raise ValueError("å°‘ãªãã¨ã‚‚2åˆ—å¿…è¦ã§ã™")
        
        # æ•°å€¤åˆ—ã®å­˜åœ¨ç¢ºèª
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        if len(numeric_columns) == 0:
            raise ValueError("æ•°å€¤åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        return df
        
    except pd.errors.ParserError as e:
        print(f"âŒ CSVè§£æã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None
```

##### 3ï¸âƒ£ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–**
```python
def optimized_analysis(filename):
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œã®æœ€é©åŒ–åˆ†æ"""
    
    # ãƒãƒ£ãƒ³ã‚¯èª­ã¿è¾¼ã¿ï¼ˆå¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‰
    chunk_size = 10000
    
    summary_results = []
    
    for chunk in pd.read_csv(filename, chunksize=chunk_size):
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«é›†è¨ˆ
        chunk_summary = chunk.groupby('Category')['Amount'].sum().reset_index()
        summary_results.append(chunk_summary)
    
    # å…¨ãƒãƒ£ãƒ³ã‚¯ã®çµæœã‚’çµ±åˆ
    final_summary = pd.concat(summary_results, ignore_index=True)
    final_summary = final_summary.groupby('Category')['Amount'].sum().reset_index()
    
    return final_summary
```

### ğŸ’¡ **é‡è¦ãªå­¦ç¿’æˆæœ**

#### ğŸ¯ **æŠ€è¡“çš„ç†è§£ã®æ·±åŒ–**

##### ğŸ“š **pandasã®çœŸã®ä¾¡å€¤**
- **ã‚¨ã‚¤ãƒªã‚¢ã‚¹è¨­è¨ˆ**: `import pandas as pd` - æ¥­ç•Œæ¨™æº–ã®åŠ¹ç‡çš„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- **ä¸€è¡Œå¤šæ©Ÿèƒ½**: `pd.read_csv()` ã§è¤‡é›‘ãªãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’å®Œå…¨è‡ªå‹•åŒ–
- **SQLçš„æ“ä½œ**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çŸ¥è­˜ãŒãã®ã¾ã¾æ´»ç”¨å¯èƒ½
- **çµ±è¨ˆçš„æ´å¯Ÿ**: `describe()` ã§ç¬æ™‚ã«ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ã‚’æŠŠæ¡

##### ğŸ”§ **ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®æœ¬è³ªç†è§£**
- **æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿**: CSVã‹ã‚‰è¡¨å½¢å¼ã¸ã®è‡ªå‹•å¤‰æ›
- **å‹ã‚·ã‚¹ãƒ†ãƒ **: æ–‡å­—åˆ—ãƒ»æ•°å€¤ãƒ»æ—¥ä»˜ã®è‡ªå‹•åˆ¤åˆ¥
- **é›†ç´„æ“ä½œ**: GROUP BYã‹ã‚‰SQLãƒ©ã‚¤ã‚¯ãªé›†è¨ˆå‡¦ç†
- **å½¢å¼å¤‰æ›**: Seriesã¨DataFrameã®é©åˆ‡ãªä½¿ã„åˆ†ã‘

##### ğŸš€ **å®Ÿç”¨çš„ä¾¡å€¤**
- **å³æˆ¦åŠ›ãƒ„ãƒ¼ãƒ«**: å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ãƒ‡ãƒ¼ã‚¿åˆ†æã«ç›´æ¥æ´»ç”¨å¯èƒ½
- **æ‹¡å¼µåŸºç›¤**: ã‚ˆã‚Šé«˜åº¦ãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹å‡¦ç†ã®åœŸå°
- **åŠ¹ç‡å‘ä¸Š**: æ‰‹å‹•è¨ˆç®—ã§ã¯ä¸å¯èƒ½ãªé€Ÿåº¦ã§ã®çµ±è¨ˆå‡¦ç†

#### ğŸŒŸ **ã€Œãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã®å®Ÿæ„Ÿ**

```python
# ã“ã®ç¾ã—ã„1è¡ŒãŒè¡¨ç¾ã™ã‚‹è¤‡é›‘ãªå‡¦ç†
df.groupby('Category')['Amount'].sum().reset_index()

# SQLæ–‡ã«å®Œå…¨å¯¾å¿œ
# SELECT Category, SUM(Amount) FROM table GROUP BY Category;

# æ‰‹å‹•è¨ˆç®—ã§ã¯æ•°åè¡Œå¿…è¦ãªå‡¦ç†ã‚’1è¡Œã§å®Œçµ
```

**pandas ã¯ã€Œãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§æ‰±ãˆã‚‹SQLã€** - ã“ã®ç†è§£ãŒä»Šå›ã®æœ€å¤§ã®åç©«ã§ã—ãŸã€‚

**sample.csv** ã¨ã„ã†å°ã•ãªãƒ‡ãƒ¼ã‚¿ã§ã‚‚ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸¦ã¿ã®é«˜åº¦ãªåˆ†æãŒ**æ‰‹è»½ã«å®Ÿè¡Œå¯èƒ½**ã§ã‚ã‚‹ç´ æ™´ã‚‰ã—ã•ã‚’å®Ÿæ„Ÿã—ã¾ã—ãŸã€‚ã“ã‚Œã“ããŒç¾ä»£ã®ãƒ‡ãƒ¼ã‚¿åˆ†æã®åŸºç›¤æŠ€è¡“ã ã¨æ·±ãç†è§£ã§ãã¾ã—ãŸã€‚

## ğŸ‰ ç·è©•

Day 69ã®CSVãƒ‡ãƒ¼ã‚¿é›†è¨ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€**pandasã®åŸºç¤ã‹ã‚‰å®Ÿç”¨ã¾ã§**ã‚’åŒ…æ‹¬çš„ã«å­¦ç¿’ã§ããŸéå¸¸ã«ä¾¡å€¤ã®é«˜ã„ä½“é¨“ã§ã—ãŸã€‚

### âœ… **ç‰¹ã«ä¾¡å€¤ãŒã‚ã£ãŸå­¦ç¿’å†…å®¹**

1. **ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã®ä¾¡å€¤**: `import pandas as pd` - åŠ¹ç‡çš„ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®åŸºæœ¬
2. **è‡ªå‹•åŒ–ã®å¨åŠ›**: `pd.read_csv()` - è¤‡é›‘ãªå‡¦ç†ã®å®Œå…¨è‡ªå‹•åŒ–
3. **çµ±è¨ˆçš„æ´å¯Ÿ**: `df.describe()` - 1è¡Œã§8ã¤ã®çµ±è¨ˆé‡ã‚’ç®—å‡º
4. **SQLãƒ©ã‚¤ã‚¯ãªæ“ä½œ**: `groupby()` - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®çŸ¥è­˜ãŒç›´æ¥æ´»ç”¨å¯èƒ½
5. **å®Ÿç”¨çš„ä¾¡å€¤**: å³åº§ã«ãƒ“ã‚¸ãƒã‚¹ã§ä½¿ãˆã‚‹é«˜æ©Ÿèƒ½åˆ†æãƒ„ãƒ¼ãƒ«
6. **è±Šå¯Œãªæ©Ÿèƒ½æ€§**: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‹ã‚‰å¯è¦–åŒ–ã¾ã§ã€åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ç’°å¢ƒ

### ğŸ¯ **ä»Šå¾Œã¸ã®å±•é–‹**

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ç¿’å¾—ã—ãŸpandasã®åŸºç¤æŠ€è¡“ã¯ã€**ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ“ã‚¸ãƒã‚¹åˆ†æ**ã®ã‚ã‚‰ã‚†ã‚‹å ´é¢ã§ç›´æ¥æ´»ç”¨ã§ãã¾ã™ã€‚ç‰¹ã«**ã€Œãƒ¡ãƒ¢ãƒªä¸Šã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€**ã¨ã„ã†æ¦‚å¿µã¯ã€ä»Šå¾Œã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«ãŠã„ã¦æ ¹å¹¹ã¨ãªã‚‹é‡è¦ãªç†è§£ã§ã™ã€‚

pandasã®**7ã¤ã®ä¸»è¦æ©Ÿèƒ½åˆ†é‡**ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«I/Oã€æŠ½å‡ºãƒ»ã‚½ãƒ¼ãƒˆã€é›†è¨ˆã€æ¬ æå€¤å‡¦ç†ã€çµåˆã€çµ±è¨ˆè¨ˆç®—ã€å¯è¦–åŒ–ï¼‰ã‚’ç†è§£ã™ã‚‹ã“ã¨ã§ã€**ãƒ‡ãƒ¼ã‚¿åˆ†æã®å…¥ã‚Šå£ã‹ã‚‰å®Ÿç”¨ã¾ã§**ã‚’ä¸€æ°—ã«é§†ã‘æŠœã‘ãŸã€ç´ æ™´ã‚‰ã—ã„å­¦ã³ã®æ—…ã§ã—ãŸï¼ğŸ“Šâœ¨
